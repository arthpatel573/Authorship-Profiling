{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TensorFlow model with AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will deploy the tensorflow model developed using AWS SageMaker service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, first create a **SageMaker Notebook instance** with instance type `ml.t2.medium`\n",
    "\n",
    "- In Permission and encryption, create a new role. Choose specific S3 buckets, then choose **Create role.**\n",
    "\n",
    "- Amazon SageMaker creates an IAM role named `AmazonSageMaker-ExecutionRole-YYYYMMDDTHHmmSS`\n",
    "\n",
    "- Copy the **IAM role ARN number**, and paste into a text file to save it temporarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and upload Dockerfile with training scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new folder named `docker_folder` in JupyterLab. Create a `Dockerfile` and copy the content of the Dockerfile present in this repo (./Dockerfile). You can modify this as per your requirements.\n",
    "\n",
    "- Upload `./scripts/train.py` and `Dockerfile` in `docker_folder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% cd ~/SageMaker/docker_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the Docker container, run the following Docker build command,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! docker build -t tf-custom-container-test ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the container to Amazon Elastic Container Registry (Amazon ECR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below script for pushing the container created to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an algorithm name\n",
    "algorithm_name=tf-custom-container-test\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account —output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest (http://amazonaws.com/$%7Balgorithm_name%7D:latest)“\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "\n",
    "$(aws ecr get-login --region ${region} —no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this container is pushed, it can be used anywhere in the SageMaker environment.\n",
    "\n",
    "We will call Amazon ECR image of the training container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "region = my_session.region_name\n",
    "\n",
    "algorithm_name = \"tf-custom-container-test\"\n",
    "ecr_image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "ecr_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `ecr_image` retrieved from the previous step to configure a SageMaker estimator object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "estimator = Estimator(image_name=ecr_image,\n",
    "    role=get_execution_role(),\n",
    "    base_job_name='tf-custom-container-test-job',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge'\n",
    ")\n",
    "\n",
    "# start training\n",
    "estimator.fit()\n",
    "\n",
    "# deploy the trained model\n",
    "predictor = estimator.deploy(1, instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless, you would want to have several sleepless nights, you should clean up all the resources.\n",
    "\n",
    "1. Open SageMaker Console, choose the notebook instance, choose Actions and click **Stop**.\n",
    "\n",
    "2. Once instance has been stopped, choose **Actions** and then **DELETE**.\n",
    "\n",
    "3. Open the Amazon S3 console and delete the bucket that you created for storing model artifacts and the training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
